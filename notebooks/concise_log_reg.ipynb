{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concise Logistic Regression for Image Classification\n",
    "\n",
    "- Shows a concise implementation of logistic regression for image classification\n",
    "- Uses PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:36:00.494320200Z",
     "start_time": "2023-05-27T07:35:54.530745400Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch #导包\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:36:00.531859400Z",
     "start_time": "2023-05-27T07:36:00.495709800Z"
    }
   },
   "outputs": [],
   "source": [
    "# download the data (uncomment if to download the data locally)\n",
    "#!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip #下载数据\n",
    "#!unzip hymenoptera_data.zip #解压文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:36:00.585570800Z",
     "start_time": "2023-05-27T07:36:00.538299900Z"
    }
   },
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "\n",
    "data_dir = 'hymenoptera_data' #数据文件\n",
    "\n",
    "# custom transformer to flatten the image tensors\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size):\n",
    "        self.new_size = new_size #初始化\n",
    "\n",
    "    def __call__(self, img):\n",
    "        result = torch.reshape(img, self.new_size) #重塑图片大小\n",
    "        return result\n",
    "\n",
    "# transformations used to standardize and normalize the datasets\n",
    "data_transforms = { #标准化规范化图像\n",
    "    'train': transforms.Compose([ #组合操作\n",
    "        transforms.Resize(224), #把图片大小转换成224\n",
    "        transforms.CenterCrop(224), #从图片中心剪裁大小为224*224的\n",
    "        transforms.ToTensor(), #将图片转化为张量\n",
    "        ReshapeTransform((-1,)) # flattens the data\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        ReshapeTransform((-1,)) # flattens the data\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# load the correspoding folders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), #从相应文件夹中加载图像\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "# load the entire dataset; we are not using minibatches here\n",
    "train_dataset = torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                            batch_size=len(image_datasets['train']),\n",
    "                                            shuffle=True) #加载训练数据集\n",
    "\n",
    "test_dataset = torch.utils.data.DataLoader(image_datasets['val'],\n",
    "                                           batch_size=len(image_datasets['val']),\n",
    "                                           shuffle=True) #加载测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:36:00.604345300Z",
     "start_time": "2023-05-27T07:36:00.589291400Z"
    }
   },
   "outputs": [],
   "source": [
    "# build the LR model\n",
    "class LR(nn.Module): #逻辑回归模型\n",
    "    def __init__(self, dim): #初始化\n",
    "        super(LR, self).__init__() #调用父类的初始化方法\n",
    "        self.linear = nn.Linear(dim, 1)\n",
    "        nn.init.zeros_(self.linear.weight) #权值置0\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x) #对x做线性变换\n",
    "        x = torch.sigmoid(x) #sigmoid函数\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:36:00.638588700Z",
     "start_time": "2023-05-27T07:36:00.606253200Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict function\n",
    "def predict(yhat, y): #预测\n",
    "    yhat = yhat.squeeze() #减少维度\n",
    "    y = y.unsqueeze(0) #在第一维上增加维度\n",
    "    y_prediction = torch.zeros(y.size()[1]) #预测结果置0\n",
    "    for i in range(yhat.shape[0]):\n",
    "        if yhat[i] <= 0.5:\n",
    "            y_prediction[i] = 0\n",
    "        else:\n",
    "            y_prediction[i] = 1\n",
    "    return 100 - torch.mean(torch.abs(y_prediction - y)) * 100 #预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T07:40:24.676346100Z",
     "start_time": "2023-05-27T07:40:24.631286900Z"
    }
   },
   "outputs": [],
   "source": [
    "# model config\n",
    "dim = train_dataset.dataset[0][0].shape[0] #获得数据维度\n",
    "lrmodel = LR(dim).to(device)\n",
    "criterion = nn.BCELoss() #对数据做二元交叉熵并且求平均\n",
    "optimizer = torch.optim.SGD(lrmodel.parameters(), lr=0.0001) #构建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931471228599548 | Train Acc: 50.40983581542969 | Test Acc: 45.75163269042969\n",
      "Cost after iteration 10: 0.6691471338272095 | Train Acc: 64.3442611694336 | Test Acc: 54.24836730957031\n",
      "Cost after iteration 20: 0.6513182520866394 | Train Acc: 68.44261932373047 | Test Acc: 54.24836730957031\n",
      "Cost after iteration 30: 0.6367825269699097 | Train Acc: 68.03278350830078 | Test Acc: 54.24836730957031\n",
      "Cost after iteration 40: 0.6245337128639221 | Train Acc: 69.67213439941406 | Test Acc: 54.90196228027344\n",
      "Cost after iteration 50: 0.6139225363731384 | Train Acc: 70.90164184570312 | Test Acc: 56.20914840698242\n",
      "Cost after iteration 60: 0.6045235395431519 | Train Acc: 72.54098510742188 | Test Acc: 56.86274337768555\n",
      "Cost after iteration 70: 0.5960512161254883 | Train Acc: 74.18032836914062 | Test Acc: 57.51633834838867\n",
      "Cost after iteration 80: 0.5883084535598755 | Train Acc: 73.77049255371094 | Test Acc: 57.51633834838867\n",
      "Cost after iteration 90: 0.5811557769775391 | Train Acc: 74.59016418457031 | Test Acc: 58.1699333190918\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "costs = [] #损失\n",
    "\n",
    "for ITER in range(100):\n",
    "    lrmodel.train() #启用BatchNormalization和 Dropout，将BatchNormalization和Dropout置为True\n",
    "    x, y = next(iter(train_dataset)) #获取训练数据集\n",
    "    test_x, test_y = next(iter(test_dataset)) #获取测试数据集\n",
    "\n",
    "    # forward\n",
    "    yhat = lrmodel.forward(x.to(device)) #正向传播\n",
    "\n",
    "    cost = criterion(yhat.squeeze(), y.type(torch.FloatTensor).to(device)) #计算损失\n",
    "    train_pred = predict(yhat, y) #预测训练结果\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad() #把梯度置0\n",
    "    cost.backward() #计算梯度\n",
    "    optimizer.step() #更新模型参数\n",
    "    \n",
    "    # evaluate\n",
    "    lrmodel.eval() #不启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为False\n",
    "    with torch.no_grad(): #torch.no_grad() 是一个上下文管理器\n",
    "        yhat_test = lrmodel.forward(test_x.to(device))\n",
    "        test_pred = predict(yhat_test, test_y) #预测测试数据\n",
    "\n",
    "    if ITER % 10 == 0:\n",
    "        costs.append(cost) #记录损失\n",
    "\n",
    "    if ITER % 10 == 0:\n",
    "        print(\"Cost after iteration {}: {} | Train Acc: {} | Test Acc: {}\".format(ITER, \n",
    "                                                                                    cost, \n",
    "                                                                                    train_pred,\n",
    "                                                                                    test_pred)) #输出损失数据\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [A Logistic Regression Model from Scratch](https://colab.research.google.com/drive/1iBoJ0kngkOthy7SgVaVQA1aHEROt5mra?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('play')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf9800998463bc980d70cdbacff0c7e9a10687346dc898569e92f016d6e252c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
